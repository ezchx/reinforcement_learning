{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "states = 6\n",
    "actions = ['left', 'right']\n",
    "episodes = 3\n",
    "epsilon = 0.9\n",
    "gamma = 0.9\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, q_table):\n",
    "    \n",
    "    if (np.random.uniform() > epsilon or q_table.iloc[state].sum() == 0): # explore - random action\n",
    "        action = np.random.choice(actions)\n",
    "    else:\n",
    "        action = q_table.iloc[state].idxmax() # exploit - action with max Q value for this state\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get new state and reward from environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_feedback(state, action):\n",
    "    \n",
    "    reward = 0\n",
    "\n",
    "    if (action == 'right'):\n",
    "        state += 1\n",
    "\n",
    "        if (state + 1 == states):\n",
    "            reward = 1\n",
    "\n",
    "    if (action == 'left'):\n",
    "\n",
    "        if (state != 0):\n",
    "            state -= 1\n",
    "    \n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_environment(state):\n",
    "    \n",
    "    environment = ''\n",
    "    \n",
    "    for position in range(states):\n",
    "        \n",
    "        if (position == states - 1):\n",
    "            environment += 'T'\n",
    "        \n",
    "        elif (position == state):\n",
    "            environment += 'o'\n",
    "            \n",
    "        else:\n",
    "            environment += '-'\n",
    "            \n",
    "    print(environment, end=\"\\r\") \n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38---T\n",
      "22---T\n",
      "9----T\n",
      "   left    right\n",
      "0   0.0  0.00000\n",
      "1   0.0  0.00000\n",
      "2   0.0  0.00081\n",
      "3   0.0  0.02520\n",
      "4   0.0  0.27100\n",
      "5   0.0  0.00000\n"
     ]
    }
   ],
   "source": [
    "q_table = pd.DataFrame(np.zeros((states, len(actions))), columns=actions)\n",
    "\n",
    "for episode in range(episodes):\n",
    "    \n",
    "    terminated = False\n",
    "    state_0 = 0\n",
    "    counter = 0\n",
    "    \n",
    "    while not terminated:\n",
    "        \n",
    "        action = choose_action(state_0, q_table)\n",
    "        \n",
    "        state_1, reward = get_env_feedback(state_0, action)\n",
    "        \n",
    "        if (reward == 1):\n",
    "            q_target = reward\n",
    "            terminated = True\n",
    "            \n",
    "        else:\n",
    "            q_target = reward + (gamma * q_table.iloc[state_1].max())\n",
    "\n",
    "        # update Q table\n",
    "        q_predict = q_table.loc[state_0, action]\n",
    "        q_table.loc[state_0, action] += alpha * (q_target - q_predict)\n",
    "        \n",
    "        state_0 = state_1\n",
    "        display_environment(state_0)\n",
    "        counter += 1\n",
    "        \n",
    "    print(counter)\n",
    "        \n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
